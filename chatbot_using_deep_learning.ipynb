{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/Co11DnlM7EJEeiaZ/BWK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mazhar31/Mazhar31/blob/main/chatbot_using_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json \n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "with open('/intents.json') as file:\n",
        "    data = json.load(file)\n",
        "    \n",
        "training_sentences = []\n",
        "training_labels = []\n",
        "labels = []\n",
        "responses = []\n",
        "\n",
        "\n",
        "for intent in data['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        training_sentences.append(pattern)\n",
        "        training_labels.append(intent['tag'])\n",
        "    responses.append(intent['responses'])\n",
        "    \n",
        "    if intent['tag'] not in labels:\n",
        "        labels.append(intent['tag'])\n",
        "        \n",
        "num_classes = len(labels)\n",
        "\n",
        "\n",
        "lbl_encoder = LabelEncoder()\n",
        "lbl_encoder.fit(training_labels)\n",
        "training_labels = lbl_encoder.transform(training_labels)\n",
        "\n",
        "\n",
        "vocab_size = 1000\n",
        "embedding_dim = 16\n",
        "max_len = 20\n",
        "oov_token = \"<OOV>\"\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)\n",
        "tokenizer.fit_on_texts(training_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
        "padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', \n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "epochs = 500\n",
        "history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)\n",
        "\n",
        "\n",
        "# to save the trained model\n",
        "model.save(\"chat_model\")\n",
        "\n",
        "import pickle\n",
        "\n",
        "# to save the fitted tokenizer\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "# to save the fitted label encoder\n",
        "with open('label_encoder.pickle', 'wb') as ecn_file:\n",
        "    pickle.dump(lbl_encoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "_mRiEm8eiEp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json \n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import colorama \n",
        "colorama.init()\n",
        "from colorama import Fore, Style, Back\n",
        "\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "with open(\"/intents.json\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "\n",
        "def chat():\n",
        "    # load trained model\n",
        "    model = keras.models.load_model('chat_model')\n",
        "\n",
        "    # load tokenizer object\n",
        "    with open('tokenizer.pickle', 'rb') as handle:\n",
        "        tokenizer = pickle.load(handle)\n",
        "\n",
        "    # load label encoder object\n",
        "    with open('label_encoder.pickle', 'rb') as enc:\n",
        "        lbl_encoder = pickle.load(enc)\n",
        "\n",
        "    # parameters\n",
        "    max_len = 20\n",
        "    \n",
        "    while True:\n",
        "        print(Fore.LIGHTBLUE_EX + \"User: \" + Style.RESET_ALL, end=\"\")\n",
        "        inp = input()\n",
        "        if inp.lower() == \"quit\":\n",
        "            break\n",
        "\n",
        "        result = model.predict(keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([inp]),\n",
        "                                             truncating='post', maxlen=max_len))\n",
        "        tag = lbl_encoder.inverse_transform([np.argmax(result)])\n",
        "\n",
        "        for i in data['intents']:\n",
        "            if i['tag'] == tag:\n",
        "                print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL , np.random.choice(i['responses']))\n",
        "\n",
        "        # print(Fore.GREEN + \"ChatBot:\" + Style.RESET_ALL,random.choice(responses))\n",
        "\n",
        "print(Fore.YELLOW + \"Start messaging with the bot (type quit to stop)!\" + Style.RESET_ALL)\n",
        "chat()"
      ],
      "metadata": {
        "id": "JUDqYvfSiexb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}